{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/olavvn/7-huggingface_practice/blob/master/huggingface_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Gd5PVm7H7o7",
    "outputId": "cc9fa50e-2f40-449c-fa3e-c5cafafea521"
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dgKU45fCffl"
   },
   "source": [
    "# 1. 허깅페이스 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6olgr_ite6K"
   },
   "source": [
    "## 실습1. BERT와 GPT-2 모델을 활용할 때 허깅페이스 트랜스포머 코드 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107,
     "referenced_widgets": [
      "701b3f3b453848c09e5a04d1bca5836a",
      "e4f77d2ffa0b44c3ab4dadb1e5b70461",
      "d5da4da0464d464ab60cb4a86ed70b3c",
      "7eed874589594740a274b25a6ddd92d2",
      "829ef11a3f084134976bd108014ace49",
      "a0eb57f8f16742eca30b63527a4b179b",
      "81b3d56e1eab4ac29f57c80a05861eca",
      "61c739067ee14a3fbbacb3b6590d2e89",
      "a392e684ea64446a994e2ced1fa2b6d6",
      "a8ca7b96b3484ca8886a688fe62f1bca",
      "08591b6c52ee4003b8b3777a47c157da"
     ]
    },
    "id": "kAwjIEiKIBVj",
    "outputId": "56a37c8c-55bc-499f-94a4-749d15610da9"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, GPT2LMHeadModel\n",
    "\n",
    "text = \"What is Huggingface Transformers?\"\n",
    "# BERT 모델 활용\n",
    "bert_model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "encoded_input = bert_tokenizer(text, return_tensors='pt')\n",
    "bert_output = bert_model(**encoded_input)\n",
    "# GPT-2 모델 활용\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "gpt_tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "encoded_input = gpt_tokenizer(text, return_tensors='pt')\n",
    "gpt_output = gpt_model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_dzN1yuPQLoT",
    "outputId": "305710a3-25e1-439c-efe2-d89d96a54f47"
   },
   "outputs": [],
   "source": [
    "bert_output #출력값: 입력 텍스트의 각 토큰과 전체 시퀀스를 나타내는 고차원의 벡터(은닉 상태)\n",
    "gpt_output #출력값: 로짓(logits) 벡터. 각 단어(토큰)가 다음에 나올 확률을 나타내는 값\n",
    "#BERT: 분류 모델로, 텍스트화 불가, GPT: 다음 단어 예측하는 모델로, 텍스트 출력하려면 별도 작업 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUIzXEp9CleZ"
   },
   "source": [
    "# 2. 트랜스포머 모델 활용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOmUG05vk3LG"
   },
   "source": [
    "## 2.1 모델 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oo8e5smt8gB"
   },
   "source": [
    "### 실습2. 모델 아이디로 바디만 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vsj_ZOu-CobD"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "base_model_id = 'bert-base-uncased'\n",
    "base_model ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WQCcAaYSZavT",
    "outputId": "e571267a-6be5-451d-d795-ff2d51434f84"
   },
   "outputs": [],
   "source": [
    "#model metadata\n",
    "base_model_config = base_model.config\n",
    "config_dict = base_model_config.__dict__\n",
    "config_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDARA5SpuJgt"
   },
   "source": [
    "### 실습3. 분류 헤드가 포함된 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XdfQpfUuCrdy",
    "outputId": "78110149-08f0-44c2-f642-b725e92169be"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "classification_model_id = 'SamLowe/roberta-base-go_emotions'\n",
    "classification_model ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eYOgjrjvafay"
   },
   "outputs": [],
   "source": [
    "#model metadata\n",
    "classification_model_config = classification_model.config\n",
    "config_dict = classification_model_config.__dict__\n",
    "config_dict\n",
    "#id2label확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPfN9HZluWeW"
   },
   "source": [
    "### 실습4. 분류 헤드가 랜덤으로 초기화된 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KnQbDV3JCtwE",
    "outputId": "dba13455-c178-407f-bad4-274d7b1233ab"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "random_model_id = 'klue/roberta-base'\n",
    "random_model ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZCGTWJXWlKgR",
    "outputId": "02dfd575-0c9d-4b9f-9ff6-f362637b8563"
   },
   "outputs": [],
   "source": [
    "#model metadata\n",
    "random_model_config = random_model.config\n",
    "config_dict = random_model_config.__dict__\n",
    "config_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqqZaxJnFOis"
   },
   "source": [
    "## 2.2 토크나이저 활용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WeYgt5UzuwGC"
   },
   "source": [
    "### 실습5. 토크나이저 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278,
     "referenced_widgets": [
      "db251b6e3b1b4383beb060f6fca61373",
      "49089e71ecfb4c5c8854c37880a6a633",
      "2917b91931cc455fb8854e030d03c55f",
      "90c73f3af1bf44fea7d32a527f54ea7a",
      "c31c0f3e7b7f40dc8629a1c7380cd6d9",
      "4550e10094b04ab88432879034e24275",
      "1a81834e604a40c8b4c86bd851c71cc6",
      "f8a87d3116e84414b32aca05b6c99ca9",
      "365c14545990429f8d599a649c0a04c5",
      "30f7c20476f24ba7883af2f1ec8443c5",
      "f5882570c72d4f709aa8b4597aa9b0d6",
      "cd8f35086df342b1a638a5509d58cb41",
      "32e447a35b52419f853087f9ece9f6bf",
      "297da98f00244f408e0d23c8cc52b225",
      "8d335ec35c8f4bafb1dcd68372120425",
      "7e24d9bae86c418b828347b67244f37b",
      "d3301c944c1243a0bf32ead92a1922c1",
      "9ece51ee537b4a39801a5cb410d0da8e",
      "eef8b42857f942728e9350e2dadd1e8d",
      "081f047fa1044dc190bc08d323336fcc",
      "084f10c308bd4cee9aba7e24e862da05",
      "cc5c917c569543df89f0f56e66da2df9",
      "5f6c13fbdd4f43849184890807e3811b",
      "dfbd9d28afa14e07a8ab85497306f759",
      "75bad1c319294ff581c74125d8534871",
      "f8282df89c21410ab6407337441dcb7a",
      "0d7f9a0645614013b4fe2dd75d2cec88",
      "3fc89a1758d94252a4a94f7729d01d6e",
      "287255fbdeef4e7990092cf0ec0ca205",
      "99e1546c88e740c783eb598dcb6678fb",
      "fd1a802033954541bfc319a776e170a3",
      "54494d1e8264440f8beb6a39cbbe33e7",
      "d4dc1bb20e8c4ae8af1e8fac3a081ab3",
      "a2e5bc8fa6314262bdcdf5b13b2ffa24",
      "6b7787cf98b74a5ca745c461fee3b16f",
      "80a49e3ec2d74760aaa071b6f45a8763",
      "5ff066015539408ab831d01ad1881aa0",
      "e66ded496d1c4484a73be4ef90479008",
      "0c6d3ca5123c4c8b8fefd2407e2ae343",
      "d7b0a8b9a57c449d87659e81d2daea84",
      "7d27b50a4cc64aa097b1892fbcfb1afc",
      "a09ae6349d6e49b88e7fc1a40c8d2e1f",
      "8c304d9cff434601a62f5d05eddc19bc",
      "d0f220d2bbe34b268550f0d3b1ee4e2c"
     ]
    },
    "id": "GOS1p907u1CO",
    "outputId": "a0c1272b-f37c-4d20-9bf8-b238e115d71b"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_id = 'klue/roberta-base'\n",
    "tokenizer ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKssSh_tu8v-"
   },
   "source": [
    "### 실습6. 토크나이저 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iaX4LD4Eu3RL",
    "outputId": "851a4e1a-4302-4c89-d6a5-09b21d31ddbe"
   },
   "outputs": [],
   "source": [
    "tokenized = tokenizer(\"토크나이저는 텍스트를 토큰 단위로 나눈다.\")\n",
    "print(tokenized)\n",
    "\n",
    "print()\n",
    "# ['[CLS]', '토크', '##나이', '##저', '##는', '텍스트', '##를', '토', '##큰', '단위', '##로', '나눈다', '[SEP]']\n",
    "\n",
    "print()\n",
    "# [CLS] 토크나이저는 텍스트를 토큰 단위로 나눈다 [SEP]\n",
    "\n",
    "print()\n",
    "# 토크나이저는 텍스트를 토큰 단위로 나눈다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjqS0r-avFl-"
   },
   "source": [
    "### 실습7. 토크나이저에 여러 문장 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vmcZndW0vGqC",
    "outputId": "418f83b9-b9ce-4856-aa9c-e00c774a2e78"
   },
   "outputs": [],
   "source": [
    "tokenizer(['첫 번째 문장', '두 번째 문장'])\n",
    "\n",
    "# {'input_ids': [[0, 1656, 1141, 3135, 6265, 2], [0, 864, 1141, 3135, 6265, 2]],\n",
    "# 'token_type_ids': [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]],\n",
    "# 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "On7iLMjHvMQd"
   },
   "source": [
    "### 실습8. 하나의 데이터에 여러 문장이 들어가는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oe9aqgr-vTOv",
    "outputId": "ae684607-09d1-49db-bce9-25844250366d"
   },
   "outputs": [],
   "source": [
    "tokenizer([['첫 번째 문장', '두 번째 문장']])\n",
    "\n",
    "# {'input_ids': [[0, 1656, 1141, 3135, 6265, 2, 864, 1141, 3135, 6265, 2]],\n",
    "# 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "# 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3oaV-a3lvcQK"
   },
   "source": [
    "### 실습9. 토큰 아이디를 문자열로 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GxIG352EvdDi",
    "outputId": "0f6e1592-5206-4243-b2f2-7336ce8d95f7"
   },
   "outputs": [],
   "source": [
    "first_tokenized_result = tokenizer(['첫 번째 문장', '두 번째 문장'])['input_ids']\n",
    "print()\n",
    "# ['[CLS] 첫 번째 문장 [SEP]', '[CLS] 두 번째 문장 [SEP]']\n",
    "\n",
    "second_tokenized_result = tokenizer([['첫 번째 문장', '두 번째 문장']])['input_ids']\n",
    "print()\n",
    "# ['[CLS] 첫 번째 문장 [SEP] 두 번째 문장 [SEP]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e22TcuvUvk3E"
   },
   "source": [
    "\n",
    "\n",
    "### 실습10. BERT 토크나이저와 RoBERTa 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0vDO4KJ_vlUv",
    "outputId": "03b08cdf-e0ed-45e2-8d60-e365595f53d8"
   },
   "outputs": [],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')\n",
    "print(bert_tokenizer([['첫 번째 문장', '두 번째 문장']]))\n",
    "\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained('klue/roberta-base')\n",
    "print(roberta_tokenizer([['첫 번째 문장', '두 번째 문장']]))\n",
    "\n",
    "en_roberta_tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "print(en_roberta_tokenizer([['first sentence', 'second sentence']]))\n",
    "\n",
    "\n",
    "#모델에 따라 토큰화 결과가 다르다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8TSCJ_rvux1"
   },
   "source": [
    "### 실습11. attention_mask 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lj8XkTM9vvwu",
    "outputId": "f63bb69e-9a26-4222-cb79-74f2c4aaf69b"
   },
   "outputs": [],
   "source": [
    "tokenizer(['첫 번째 문장은 짧다.', '두 번째 문장은 첫 번째 문장 보다 더 길다.'], padding='longest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9hRNhL6v8J3"
   },
   "source": [
    "# 3. 데이터셋 활용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jciuyy3G3Pv5"
   },
   "source": [
    "## 3.1 데이터셋 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsihUpKB3hKx"
   },
   "source": [
    "### 실습12. 허깅페이스 허브에서 데이터셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h6rED4n6v-dg",
    "outputId": "0e99049e-1866-4dc8-d5c0-427d8e5cb973"
   },
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "\n",
    "from datasets import load_dataset\n",
    "klue_mrc_dataset =\n",
    "klue_mrc_dataset_only_train ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oYQcIJmIOcyH",
    "outputId": "38ba6ea4-b653-484b-b33f-a1697f96af34"
   },
   "outputs": [],
   "source": [
    "klue_mrc_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vfVetDobOoiQ",
    "outputId": "71a6d981-0ae6-4bf6-9bf5-27d8bf07fa94"
   },
   "outputs": [],
   "source": [
    "klue_mrc_dataset_only_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k4dqLQJIOzQO",
    "outputId": "bb3c0d77-7d52-4dfb-bc61-916b58487020"
   },
   "outputs": [],
   "source": [
    "klue_mrc_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28cdd3vPwF-x"
   },
   "source": [
    "### 실습13. 로컬의 데이터 활용하기\n",
    "(안내) 아래 코드를 실행하기 위해서는 구글 코랩에 csv 파일이 업로드 되어야 합니다. 허깅페이스 datasets 형식으로 쉽게 변환할 수 있다는 점을 보여주기 위한 예시 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VByKyjBcMjfs",
    "outputId": "5988d4f5-2158-4959-8ed5-bcc2ea2e5bf0"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c7FfgbFUDBQg",
    "outputId": "e8422fd4-5622-4955-99ec-5cb49635213c"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "# 로컬의 데이터 파일을 활용\n",
    "dataset_json =\n",
    "print(dataset_json)\n",
    "dataset_json_train =\n",
    "print(dataset_json_train)\n",
    "#로컬 데이터로는 train 100% default.\n",
    "dataset_json_test =\n",
    "print(dataset_json_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gAk3WHRuRiGw",
    "outputId": "c6381616-6768-45d2-af18-a1d873291a3c"
   },
   "outputs": [],
   "source": [
    "print(dataset_json['train'][0])\n",
    "print(dataset_json_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OE1cIGmdwT8n"
   },
   "source": [
    "\n",
    "### 실습14. 데이터셋 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uJ5E8b1lP7yN",
    "outputId": "e5b465d4-e2d1-4d54-fc89-60a6a8f0948f"
   },
   "outputs": [],
   "source": [
    "# 파이썬 딕셔너리 활용\n",
    "from datasets import Dataset\n",
    "my_dict = {\"a\": [1, 2, 3]}\n",
    "dataset = Dataset.from_dict(my_dict)\n",
    "print(dataset[0])\n",
    "\n",
    "# 판다스 데이터프레임 활용\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"a\": [1, 2, 3]})\n",
    "dataset = Dataset.from_pandas(df)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbdIGz7YDQ8q"
   },
   "source": [
    "## 3.2. 데이터셋 가공하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qnb6SqInweAW"
   },
   "source": [
    "### 실습15. 실습에 사용하지 않는 불필요한 컬럼 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uHjb8Rd6DSDh",
    "outputId": "8a2227ed-9cb9-4f2d-948f-a9d3c1ef4c5c"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "klue_tc_train =\n",
    "klue_tc_eval =\n",
    "print(klue_tc_train)\n",
    "print(klue_tc_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wr6cX9laDX9Z",
    "outputId": "1c079717-3689-45d5-9db3-ae398bc54ed9"
   },
   "outputs": [],
   "source": [
    "klue_tc_train_removed =\n",
    "klue_tc_eval_removed =\n",
    "print(klue_tc_train_removed)\n",
    "print(klue_tc_train_removed[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAjvDdjqwoXY"
   },
   "source": [
    "### 실습16. 카테고리를 문자로 표기한 label_str 컬럼 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z90M9sisDUmr",
    "outputId": "4f9f5087-7dfc-4ea1-9f6b-439ef5a2c194"
   },
   "outputs": [],
   "source": [
    "print(klue_tc_train_removed.features['title'])\n",
    "print(klue_tc_train_removed.features['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 99,
     "referenced_widgets": [
      "f64eb605da2746f6bdec2ed18001c124",
      "16139e0ce2b44b168bf71f465392a749",
      "7f611a33650a41d08af21d12aafad22d",
      "2ecae076f6e64962a5a526364ed33e1f",
      "055703b786164768847636700c2ffcb9",
      "f9d90c7c189a471693e1d694f64d10d8",
      "3cbd54779d9d48ceb5cd3a0cef2f447a",
      "02e7daa745df43b7996c121c7eefe78e",
      "3ab4c6e4a8964c48b454213aeed415ed",
      "808c59c7dfae4e1080fecb3de972193f",
      "d2c454619a234385921d34f203d00f25",
      "a9051fd823cb4f5195cdc2cfa5880f9f",
      "46dae93111cf43b8ae7f8283448dc048",
      "f4982f41a9ff47df9821a89bd8712bcd",
      "c82b24f4a37446028ad5db33f176ace4",
      "96b0c159db324fa88266a339380d472d",
      "3735722c8aef4e3792fcf590c133cdcd",
      "c18708c6451447179c901a88043c1ad6",
      "07fe40ccd35447d49db76c71b740bed9",
      "d13bb476013049e69796072a6945528a",
      "7e3cdc1c4cf34628b9edbe9402760e73",
      "61b112144dcd437093df68c6d9aa2391"
     ]
    },
    "id": "W2YoqY7jDZVN",
    "outputId": "89778d8f-639c-4a8e-cf6b-deec44cca636"
   },
   "outputs": [],
   "source": [
    "klue_tc_label = klue_tc_train_removed.features['label']\n",
    "\n",
    "def make_str_label(batch):\n",
    "\n",
    "  return batch\n",
    "\n",
    "klue_tc_train_removed =\n",
    "klue_tc_eval_removed =\n",
    "\n",
    "klue_tc_train_removed[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzAkPNnmwumM"
   },
   "source": [
    "### 실습17. 학습/검증/테스트 데이터셋 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xNbew6U5Da9r"
   },
   "outputs": [],
   "source": [
    "train_dataset = klue_tc_train_removed.train_test_split(test_size=10000, shuffle=True, seed=42)['test']\n",
    "dataset = klue_tc_eval_removed.train_test_split(test_size=1000, shuffle=True, seed=42)\n",
    "test_dataset = dataset['test']\n",
    "valid_dataset = dataset['train'].train_test_split(test_size=1000, shuffle=True, seed=42)['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WheFaA_obmWG"
   },
   "source": [
    "# 4. 모델을 이용하여 추론하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrzXul13ygjb"
   },
   "source": [
    "### 실습18. 학습한 모델을 불러와 pipeline을 활용해 텍스트 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hQojQCo9boGv",
    "outputId": "8bed0473-bcf6-4f78-d620-421eb00f54c5"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"hykiim/roberta-base-klue-ynat-classification\"\n",
    "\n",
    "model_pipeline =\n",
    "\n",
    "model_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJoFN-mEysQF"
   },
   "source": [
    "### 실습19. 커스텀 파이프라인 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3k6Q34dJjkC3",
    "outputId": "dfd1c88d-a987-474e-9217-a265ce31d90a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "class CustomPipeline:\n",
    "    def __init__(self, model_id):\n",
    "        self.model = #목적에 맞는 모델 헤드 불러옴\n",
    "        self.tokenizer = #모델과 동일한 토크나이저 불러옴\n",
    "        self.model.eval() #모델 평가 모드\n",
    "\n",
    "    def __call__(self, texts):\n",
    "        tokenized = self.tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)# 입력 텍스트를 토크나이저를 사용하여 토큰화\n",
    "        # return_tensors=\"pt\": PyTorch 텐서로 반환, padding=True: 패딩 추가, truncation=True: 잘라내기\n",
    "\n",
    "        with torch.no_grad():#기울기 계산 비활성화(옵티마이저 계산 생략)-> 추론 과정에서는 옵티마이징 할 필요 없음.\n",
    "            outputs = self.model(**tokenized)#**연산자는 딕셔너리를 키워드 인자로 unpacking하여 모델에 입력. 즉 토큰 아이디\n",
    "            logits = outputs.logits# 모델 출력에서 logits 값을 추출. (분류되지 않은 예측값)\n",
    "\n",
    "        #추론이 정확할 확률 구하기\n",
    "        probabilities = softmax(logits, dim=-1)\n",
    "        scores, labels = torch.max(probabilities, dim=-1)\n",
    "        labels_str = [self.model.config.id2label[label_idx] for label_idx in labels.tolist()]\n",
    "\n",
    "        return [{\"label\": label, \"score\": score.item()} for label, score in zip(labels_str, scores)]\n",
    "\n",
    "custom_pipeline = CustomPipeline(model_id)\n",
    "print(custom_pipeline(test_dataset['title'][:5]))\n",
    "print(test_dataset['label_str'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2z1j014MUX8V",
    "outputId": "c5571973-96d9-4521-c5c1-9a251fbba8fd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "gpt_tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "encoded_input = gpt_tokenizer(text, return_tensors='pt')\n",
    "gpt_output = gpt_model(**encoded_input)\n",
    "\n",
    "\n",
    "# GPT-2는 기본 pad 토큰이 없으므로, eos 토큰을 pad 토큰으로 설정 (일반적인 관행)\n",
    "if gpt_tokenizer.pad_token is None:\n",
    "    gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
    "\n",
    "# 2. 입력 텍스트 준비\n",
    "text = \"What is Huggingface Transformer?\"\n",
    "encoded_input = gpt_tokenizer(text, return_tensors='pt')\n",
    "input_ids = encoded_input['input_ids']\n",
    "\n",
    "# 3. 텍스트 생성 (model.generate 사용)\n",
    "# max_length: 생성될 텍스트의 최대 길이 (입력 포함)\n",
    "# num_return_sequences: 생성할 시퀀스 수\n",
    "# pad_token_id: 패딩에 사용될 토큰 ID 설정\n",
    "output_sequences = gpt_model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=50,  # 예시: 최대 50 토큰까지 생성\n",
    "    num_return_sequences=1,\n",
    "    pad_token_id=gpt_tokenizer.pad_token_id,\n",
    "    # 더 다양한 결과를 원하면 다음 파라미터 추가 가능:\n",
    "    do_sample=True,      # 샘플링 사용 여부\n",
    "    top_k=50,            # 상위 K개 토큰 중에서만 샘플링\n",
    "    top_p=0.95,          # 누적 확률 P 이상인 토큰 중에서만 샘플링 (nucleus sampling)\n",
    "    temperature=0.7,     # 확률 분포를 조절 (낮을수록 결정적, 높을수록 무작위적)\n",
    ")\n",
    "\n",
    "# 4. 생성된 토큰 ID 시퀀스를 텍스트로 디코딩\n",
    "# output_sequences[0]은 생성된 첫 번째 시퀀스를 의미\n",
    "# skip_special_tokens=True 옵션은 <|endoftext|> 같은 특수 토큰을 결과에서 제외\n",
    "generated_text = gpt_tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
    "\n",
    "# 5. 결과 출력\n",
    "print(\"Input Text:\", text)\n",
    "print(\"Generated Text:\", generated_text)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "hateslop1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
